{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation results \n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "def eval_model(model, test_images, test_labels):\n",
    "    y_pred = model.predict(test_images)\n",
    "    y_pred = y_pred = np.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    acc = accuracy_score(test_labels, y_pred)\n",
    "    precision = precision_score(test_labels, y_pred, average='macro')\n",
    "    recall = recall_score(test_labels, y_pred, average='macro')\n",
    "        \n",
    "    print(\"Accuracy: \" + str(np.mean(acc)))\n",
    "    print(\"Precision: \" + str(np.mean(precision)))\n",
    "    print(\"Recall: \" + str(np.mean(recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.image import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cifar10', 'mnist']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = 'C:/Users/MINH LE/Desktop/TraditionalvsCNN/Additional Experiments/minh_dataset/'\n",
    "\n",
    "list_files = os.listdir(DATA_DIR)\n",
    "number_files = len(list_files)\n",
    "list_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLTP Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, cv2\n",
    "cltp = []\n",
    "\n",
    "CLTP_DIR = DATA_DIR + 'mnist/cltp/test/'\n",
    "for img in glob.glob(CLTP_DIR + '*.jpg'):\n",
    "    n = cv2.imread(img, 0)\n",
    "    cltp.append(n)\n",
    "    \n",
    "cltp = np.asarray(cltp, dtype=np.float32)\n",
    "cltp = np.reshape(cltp, (10000, 28, 28, 1))\n",
    "cltp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSLBP Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cslbp = []\n",
    "\n",
    "CSLBP_DIR = DATA_DIR + 'mnist/cslbp/test/'\n",
    "for img in glob.glob(CSLBP_DIR + '*.jpg'):\n",
    "    n = cv2.imread(img, 0)\n",
    "    cslbp.append(n)\n",
    "    \n",
    "cslbp = np.asarray(cslbp, dtype=np.float32)\n",
    "cslbp = np.reshape(cslbp, (10000, 28, 28, 1))\n",
    "cslbp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_filter = []\n",
    "\n",
    "GAUSSIAN_DIR = DATA_DIR + 'mnist/gaussian/test/'\n",
    "for img in glob.glob(GAUSSIAN_DIR + '*.jpg'):\n",
    "    n = cv2.imread(img, 0)\n",
    "    gauss_filter.append(n)\n",
    "    \n",
    "gauss_filter = np.asarray(gauss_filter, dtype=np.float32)\n",
    "gauss_filter = np.reshape(gauss_filter, (10000, 28, 28, 1))\n",
    "gauss_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLTP Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gltp_filter = []\n",
    "\n",
    "GLTP_DIR = DATA_DIR + 'mnist/gltp/test/'\n",
    "for img in glob.glob(GLTP_DIR + '*.jpg'):\n",
    "    n = cv2.imread(img, 0)\n",
    "    gltp_filter.append(n)\n",
    "    \n",
    "gltp_filter = np.asarray(gltp_filter, dtype=np.float32)\n",
    "gltp_filter = np.reshape(gltp_filter, (10000, 28, 28, 1))\n",
    "gltp_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplacian_filter = []\n",
    "\n",
    "LAPLACIAN_DIR = DATA_DIR + 'mnist/laplacian/test/'\n",
    "for img in glob.glob(LAPLACIAN_DIR + '*.jpg'):\n",
    "    n = cv2.imread(img, 0)\n",
    "    laplacian_filter.append(n)\n",
    "    \n",
    "laplacian_filter = np.asarray(laplacian_filter, dtype=np.float32)\n",
    "laplacian_filter = np.reshape(laplacian_filter, (10000, 28, 28, 1))\n",
    "laplacian_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Binary Pattern Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbp_filter = []\n",
    "\n",
    "LBP_DIR = DATA_DIR + 'mnist/lbp/test/'\n",
    "for img in glob.glob(LBP_DIR + '*.jpg'):\n",
    "    n = cv2.imread(img, 0)\n",
    "    lbp_filter.append(n)\n",
    "    \n",
    "lbp_filter = np.asarray(lbp_filter, dtype=np.float32)\n",
    "lbp_filter = np.reshape(lbp_filter, (10000, 28, 28, 1))\n",
    "lbp_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Ternary Pattern Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltp_filter = []\n",
    "\n",
    "LTP_DIR = DATA_DIR + 'mnist/ltp/test/'\n",
    "for img in glob.glob(LTP_DIR + '*.jpg'):\n",
    "    n = cv2.imread(img, 0)\n",
    "    ltp_filter.append(n)\n",
    "    \n",
    "ltp_filter = np.asarray(ltp_filter, dtype=np.float32)\n",
    "ltp_filter = np.reshape(ltp_filter, (10000, 28, 28, 1))\n",
    "ltp_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prewitt X Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prewittx_filter = []\n",
    "\n",
    "PREWITTX_DIR = DATA_DIR + 'mnist/prewittx/test/'\n",
    "for img in glob.glob(PREWITTX_DIR + '*.jpg'):\n",
    "    n = cv2.imread(img, 0)\n",
    "    prewittx_filter.append(n)\n",
    "    \n",
    "prewittx_filter = np.asarray(prewittx_filter, dtype=np.float32)\n",
    "prewittx_filter = np.reshape(prewittx_filter, (10000, 28, 28, 1))\n",
    "prewittx_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prewitt Y Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prewitty_filter = []\n",
    "\n",
    "PREWITTY_DIR = DATA_DIR + 'mnist/prewitty/test/'\n",
    "for img in glob.glob(PREWITTY_DIR + '*.jpg'):\n",
    "    n = cv2.imread(img, 0)\n",
    "    prewitty_filter.append(n)\n",
    "    \n",
    "prewitty_filter = np.asarray(prewitty_filter, dtype=np.float32)\n",
    "prewitty_filter = np.reshape(prewitty_filter, (10000, 28, 28, 1))\n",
    "prewitty_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCS-LTP Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scsltp_filter = []\n",
    "\n",
    "SCSLTP_DIR = DATA_DIR + 'mnist/scsltp/test/'\n",
    "for img in glob.glob(SCSLTP_DIR + '*.jpg'):\n",
    "    n = cv2.imread(img, 0)\n",
    "    scsltp_filter.append(n)\n",
    "    \n",
    "scsltp_filter = np.asarray(scsltp_filter, dtype=np.float32)\n",
    "scsltp_filter = np.reshape(scsltp_filter, (10000, 28, 28, 1))\n",
    "scsltp_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SILTP Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siltp_filter = []\n",
    "\n",
    "SILTP_DIR = DATA_DIR + 'mnist/siltp/test/'\n",
    "for img in glob.glob(SILTP_DIR + '*.jpg'):\n",
    "    n = cv2.imread(img, 0)\n",
    "    siltp_filter.append(n)\n",
    "    \n",
    "siltp_filter = np.asarray(siltp_filter, dtype=np.float32)\n",
    "siltp_filter = np.reshape(siltp_filter, (10000, 28, 28, 1))\n",
    "siltp_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel X Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sobelx_filter = []\n",
    "\n",
    "SOBELX_DIR = DATA_DIR + 'mnist/sobelx/test/'\n",
    "for img in glob.glob(SOBELX_DIR + '*.jpg'):\n",
    "    n = cv2.imread(img, 0)\n",
    "    sobelx_filter.append(n)\n",
    "    \n",
    "sobelx_filter = np.asarray(sobelx_filter, dtype=np.float32)\n",
    "sobelx_filter = np.reshape(sobelx_filter, (10000, 28, 28, 1))\n",
    "sobelx_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel Y Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sobely_filter = []\n",
    "\n",
    "SOBELY_DIR = DATA_DIR + 'mnist/sobely/test/'\n",
    "for img in glob.glob(SOBELY_DIR + '*.jpg'):\n",
    "    n = cv2.imread(img, 0)\n",
    "    sobely_filter.append(n)\n",
    "    \n",
    "sobely_filter = np.asarray(sobely_filter, dtype=np.float32)\n",
    "sobely_filter = np.reshape(sobely_filter, (10000, 28, 28, 1))\n",
    "sobely_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XCSLTP Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xcsltp_filter = []\n",
    "\n",
    "XCSLTP_DIR = DATA_DIR + 'mnist/xcsltp/test/'\n",
    "for img in glob.glob(XCSLTP_DIR + '*.jpg'):\n",
    "    n = cv2.imread(img, 0)\n",
    "    xcsltp_filter.append(n)\n",
    "    \n",
    "xcsltp_filter = np.asarray(xcsltp_filter, dtype=np.float32)\n",
    "xcsltp_filter = np.reshape(xcsltp_filter, (10000, 28, 28, 1))\n",
    "xcsltp_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diverse Brightness Test Data (T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(_, _), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "test_images = test_images / 255.\n",
    "\n",
    "test_images = tf.reshape(test_images, (10000, 28, 28, 1))\n",
    "test_labels = tf.reshape(test_labels, (10000, 1))\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call Test Data T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cifar10', 'mnist']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = 'C:/Users/MINH LE/Desktop/TraditionalvsCNN/testset-T2/'\n",
    "\n",
    "list_files = os.listdir(DATA_DIR)\n",
    "number_files = len(list_files)\n",
    "list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 28, 28, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test_t2_images = []\n",
    "\n",
    "MNIST_T2_DIR = DATA_DIR + 'mnist/'\n",
    "for img in glob.glob(MNIST_T2_DIR + '*.png'):\n",
    "    n = cv2.imread(img, 0)\n",
    "    mnist_test_t2_images.append(n)\n",
    "\n",
    "\n",
    "mnist_test_t2_images = tf.convert_to_tensor(mnist_test_t2_images, dtype=np.float32)\n",
    "mnist_test_t2_images = mnist_test_t2_images / 255.\n",
    "mnist_test_t2_images = tf.reshape(mnist_test_t2_images, [10000, 28, 28, 1])\n",
    "mnist_test_t2_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 28, 28, 15])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = tf.keras.layers.Concatenate()([cltp, \n",
    "                                            cslbp, \n",
    "                                            gauss_filter, \n",
    "                                            gltp_filter,\n",
    "                                            laplacian_filter,\n",
    "                                            lbp_filter,\n",
    "                                            ltp_filter,\n",
    "                                            prewittx_filter,\n",
    "                                            prewitty_filter,\n",
    "                                            scsltp_filter,\n",
    "                                            siltp_filter,\n",
    "                                            sobelx_filter,\n",
    "                                            sobely_filter,\n",
    "                                            xcsltp_filter,\n",
    "                                           mnist_test_t2_images])\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(r'C:\\Users\\MINH LE\\Desktop\\TraditionalvsCNN\\Additional Experiments\\mnist\\models\\model_combined_traditionalcnn_mnist_t2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1066\n",
      "Precision: 0.10316986683647562\n",
      "Recall: 0.10122329810142876\n"
     ]
    }
   ],
   "source": [
    "eval_model(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
